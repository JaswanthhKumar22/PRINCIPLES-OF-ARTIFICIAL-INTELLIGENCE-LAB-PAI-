{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98ff547d",
   "metadata": {},
   "source": [
    "# Vacuum Cleaner Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32a8497e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suck\n"
     ]
    }
   ],
   "source": [
    "class vaccumagent:\n",
    "    def __init__(self):\n",
    "        self.location = 'A'\n",
    "        \n",
    "    def act(self,percept):\n",
    "        location, status = percept\n",
    "        if status == 'Dirty':\n",
    "            return 'suck'\n",
    "        elif location == 'A':\n",
    "            return 'Right'\n",
    "        else :\n",
    "            return 'Left'\n",
    "        \n",
    "        \n",
    "\n",
    "agent = vaccumagent()\n",
    "print(agent.act(('A','Dirty')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a408ba",
   "metadata": {},
   "source": [
    "# Simple Reflex Agent in a 4-Room Grid Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08a12787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 01: position=(0,0) Status=Dirty Action =suck\n",
      "step 02: position=(1,0) Status=clean Action =down\n",
      "step 03: position=(1,1) Status=Clean Action =right\n",
      "step 04: position=(1,1) Status=Dirty Action =suck\n",
      "step 05: position=(0,1) Status=clean Action =up\n",
      "step 06: position=(0,1) Status=Dirty Action =suck\n",
      "step 07: position=(0,0) Status=clean Action =left\n",
      "step 08: position=(1,0) Status=clean Action =down\n",
      "step 09: position=(0,0) Status=Clean Action =up\n",
      "step 10: position=(0,1) Status=clean Action =right\n",
      "step 11: position=(0,0) Status=clean Action =left\n",
      "step 12: position=(0,1) Status=clean Action =right\n",
      "step 13: position=(1,1) Status=clean Action =down\n",
      "step 14: position=(0,1) Status=clean Action =up\n",
      "step 15: position=(0,0) Status=clean Action =left\n",
      "step 16: position=(1,0) Status=clean Action =down\n",
      "step 17: position=(1,1) Status=Clean Action =right\n",
      "step 18: position=(0,1) Status=clean Action =up\n",
      "step 19: position=(1,1) Status=clean Action =down\n",
      "step 20: position=(0,1) Status=clean Action =up\n",
      "step 21: position=(1,1) Status=clean Action =down\n",
      "step 22: position=(1,0) Status=clean Action =left\n",
      "step 23: position=(0,0) Status=Clean Action =up\n",
      "step 24: position=(0,1) Status=clean Action =right\n",
      "step 25: position=(1,1) Status=clean Action =down\n",
      "step 26: position=(0,1) Status=clean Action =up\n",
      "step 27: position=(1,1) Status=clean Action =down\n",
      "step 28: position=(1,0) Status=clean Action =left\n",
      "step 29: position=(1,1) Status=Clean Action =right\n",
      "step 30: position=(1,0) Status=clean Action =left\n",
      "step 31: position=(0,0) Status=Clean Action =up\n",
      "step 32: position=(1,0) Status=clean Action =down\n",
      "step 33: position=(0,0) Status=Clean Action =up\n",
      "step 34: position=(0,1) Status=clean Action =right\n",
      "step 35: position=(0,0) Status=clean Action =left\n",
      "step 36: position=(1,0) Status=clean Action =down\n",
      "step 37: position=(0,0) Status=Clean Action =up\n",
      "step 38: position=(0,1) Status=clean Action =right\n",
      "step 39: position=(0,0) Status=clean Action =left\n",
      "step 40: position=(0,1) Status=clean Action =right\n",
      "step 41: position=(0,0) Status=clean Action =left\n",
      "step 42: position=(1,0) Status=clean Action =down\n",
      "step 43: position=(1,1) Status=Clean Action =right\n",
      "step 44: position=(0,1) Status=clean Action =up\n",
      "step 45: position=(0,0) Status=clean Action =left\n",
      "step 46: position=(0,1) Status=clean Action =right\n",
      "step 47: position=(1,1) Status=clean Action =down\n",
      "step 48: position=(0,1) Status=clean Action =up\n",
      "step 49: position=(0,0) Status=clean Action =left\n",
      "step 50: position=(1,0) Status=clean Action =down\n",
      "\n",
      "Room cleaned: 3\n",
      "TOtal movements: 47\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "grid_size=2\n",
    "steps=50\n",
    "\n",
    "env=[]\n",
    "for i in range(grid_size):\n",
    "    row =[]\n",
    "    for j in range(grid_size):\n",
    "        row.append(random.choice([\"Dirty\",\"Clean\"]))\n",
    "    env.append(row)\n",
    "    \n",
    "\n",
    "agent_x,agent_y=random.randint(0,1),random.randint(0,1)\n",
    "rooms_cleaned=0\n",
    "movements=0\n",
    "\n",
    "def get_valid_moves(x,y):\n",
    "    moves=[]\n",
    "    if x>0:\n",
    "        moves.append(\"up\")\n",
    "    if x<grid_size-1:\n",
    "        moves.append(\"down\")\n",
    "    if y>0:\n",
    "        moves.append(\"left\")\n",
    "    if y<grid_size-1:\n",
    "        moves.append(\"right\")\n",
    "    return moves\n",
    "\n",
    "def reflex_agent(x,y,status):\n",
    "    if status==\"Dirty\":\n",
    "        return \"suck\"\n",
    "    else:\n",
    "        return random.choice(get_valid_moves(x,y))\n",
    "\n",
    "for step in range(steps):\n",
    "    status=env[agent_x][agent_y]\n",
    "    action=reflex_agent(agent_x,agent_y,status)\n",
    "    \n",
    "    if action==\"suck\":\n",
    "        env[agent_x][agent_y]=\"clean\"\n",
    "        rooms_cleaned += 1\n",
    "    else:\n",
    "        if action==\"up\":\n",
    "            agent_x-=1\n",
    "        elif action==\"down\":\n",
    "            agent_x+=1\n",
    "        elif action==\"right\":\n",
    "            agent_y+=1\n",
    "        elif action==\"left\":\n",
    "            agent_y-=1\n",
    "        movements+=1  \n",
    "        \n",
    "    print(f\"step {step+1:02d}: position=({agent_x},{agent_y}) Status={status} Action ={action}\")\n",
    "    \n",
    "print(\"\\nRoom cleaned:\", rooms_cleaned)\n",
    "print(\"TOtal movements:\",movements)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4825f23",
   "metadata": {},
   "source": [
    "# Model-Based Vacuum Cleaner Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8fc3f1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 01: Position=(1,0) Percept=Clean Action=left\n",
      "Step 02: Position=(0,0) Percept=Clean Action=up\n",
      "Step 03: Position=(0,1) Percept=Clean Action=right\n",
      "Step 04: Position=(0,1) Percept=Dirty Action=suck\n",
      "\n",
      "All rooms are known and clean. Stopping simulation.\n",
      "\n",
      "Rooms cleaned: 1\n",
      "Total movements: 3\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "grid_size = 2\n",
    "steps = 50\n",
    "env = []\n",
    "for i in range(grid_size):\n",
    "    row = []\n",
    "    for j in range(grid_size):\n",
    "        row.append(random.choice([\"Dirty\", \"Clean\"]))\n",
    "    env.append(row)\n",
    "agent_x, agent_y = random.randint(0, 1), random.randint(0, 1)\n",
    "model = [[\"Unknown\" for _ in range(grid_size)] for _ in range(grid_size)]\n",
    "rooms_cleaned = 0\n",
    "movements = 0\n",
    "def get_valid_moves(x, y):\n",
    "    moves = []\n",
    "    if x > 0:\n",
    "        moves.append((\"up\", x-1, y))\n",
    "    if x < grid_size - 1:\n",
    "        moves.append((\"down\", x+1, y))\n",
    "    if y > 0:\n",
    "        moves.append((\"left\", x, y-1))\n",
    "    if y < grid_size - 1:\n",
    "        moves.append((\"right\", x, y+1))\n",
    "    return moves\n",
    "def model_based_agent(x, y, status):\n",
    "    model[x][y] = status\n",
    "    if status == \"Dirty\":\n",
    "        return \"suck\"\n",
    "    moves = get_valid_moves(x, y)\n",
    "    preferred = []\n",
    "    fallback = []\n",
    "    for move, nx, ny in moves:\n",
    "        if model[nx][ny] == \"Unknown\" or model[nx][ny] == \"Dirty\":\n",
    "            preferred.append(move)\n",
    "        else:\n",
    "            fallback.append(move)\n",
    "    if preferred:\n",
    "        return random.choice(preferred)\n",
    "    else:\n",
    "        return random.choice(fallback)\n",
    "for step in range(steps):\n",
    "    status = env[agent_x][agent_y]\n",
    "    action = model_based_agent(agent_x, agent_y, status)\n",
    "    if action == \"suck\":\n",
    "        env[agent_x][agent_y] = \"Clean\"\n",
    "        model[agent_x][agent_y] = \"Clean\"\n",
    "        rooms_cleaned += 1\n",
    "    else:\n",
    "        if action == \"up\":\n",
    "            agent_x -= 1\n",
    "        elif action == \"down\":\n",
    "            agent_x += 1\n",
    "        elif action == \"right\":\n",
    "            agent_y += 1\n",
    "        elif action == \"left\":\n",
    "            agent_y -= 1\n",
    "        movements += 1\n",
    "    print(f\"Step {step+1:02d}: Position=({agent_x},{agent_y}) \"\n",
    "          f\"Percept={status} Action={action}\")\n",
    "    all_clean = True\n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            if model[i][j] != \"Clean\":\n",
    "                all_clean = False\n",
    "    if all_clean:\n",
    "        print(\"\\nAll rooms are known and clean. Stopping simulation.\")\n",
    "        break\n",
    "\n",
    "print(\"\\nRooms cleaned:\", rooms_cleaned)\n",
    "print(\"Total movements:\", movements)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7ba37e",
   "metadata": {},
   "source": [
    "# 1. Why does the simple reflex agent perform redundant actions in the grid environment?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e9ce0be",
   "metadata": {},
   "source": [
    "The simple reflex agent has no memory of previously visited rooms.\n",
    "It reacts only to the current roomâ€™s status and moves randomly when it is clean.\n",
    "Because of this, it often revisits rooms that are already clean.\n",
    "This causes unnecessary back-and-forth movements and redundant actions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dbcbe6",
   "metadata": {},
   "source": [
    "# 2. How does the internal model improve agent performance?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ae7e3787",
   "metadata": {},
   "source": [
    "The internal model allows the agent to remember the cleanliness of visited rooms.\n",
    "It avoids moving into rooms already known to be clean.\n",
    "The agent prefers unvisited or dirty rooms, guiding it efficiently.\n",
    "This reduces redundant movements and speeds up cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6c5f7",
   "metadata": {},
   "source": [
    "# 3. Compare the simple reflex and model-based agents in terms of:\n",
    "#   a. Rationality\n",
    "#   b. Efficiency\n",
    " #  c. Scalability"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ab9d362a",
   "metadata": {},
   "source": [
    "a. Rationality\n",
    "\n",
    "Simple Reflex Agent: Acts only on the current percept, without considering past actions.\n",
    "\n",
    "Model-Based Agent: Uses memory of visited rooms, making more informed and rational decisions.\n",
    "\n",
    "b. Efficiency\n",
    "\n",
    "Simple Reflex Agent: Performs many redundant moves by revisiting clean rooms.\n",
    "\n",
    "Model-Based Agent: Minimizes unnecessary movements by targeting unvisited or dirty rooms.\n",
    "\n",
    "c. Scalability\n",
    "\n",
    "Simple Reflex Agent: Becomes highly inefficient as grid size increases.\n",
    "\n",
    "Model-Based Agent: Scales better to larger environments due to its internal model and planning ability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc6680e",
   "metadata": {},
   "source": [
    "# 4. Would the model-based agent still work correctly in a partially observable environment? Justify."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d82ffd27",
   "metadata": {},
   "source": [
    "Yes, a model-based agent can still work in a partially observable environment because it maintains an internal model to fill in missing information.\n",
    "It uses past percepts to infer the state of unseen rooms and guide actions.\n",
    "However, its performance may degrade if the environment changes or percepts are inaccurate.\n",
    "In such cases, the model may become outdated, leading to suboptimal decisions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
